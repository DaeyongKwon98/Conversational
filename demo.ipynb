{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "from ast import literal_eval\n",
    "from torch import cuda\n",
    "import json\n",
    "device = 'cuda:0' if cuda.is_available() else 'cpu'\n",
    "\n",
    "user_intents = ['initial_query', 'greeting', 'add_filter', 'remove_filter', 'continue', 'accept_response', 'reject_response', 'others']\n",
    "system_intents = ['feedback_request', 'detail_attribute_request', 'passive_recommend', 'active_recommend', 'parroting_response', 'sympathetic_response', 'others']\n",
    "music_attributes = ['track', 'artist', 'year', 'popularity', 'culture', 'similar_track', 'similar_artist', 'user', 'theme', 'mood', 'genre', 'instrument', 'vocal', 'tempo', 'none']\n",
    "intents_dict = {'user': user_intents, 'system': system_intents, 'music': music_attributes}\n",
    "\n",
    "df = pd.read_csv('./most_recent.csv', encoding='unicode_escape')\n",
    "df['intent'] = df['intent'].apply(literal_eval)\n",
    "df['music_attribute'] = df['music_attribute'].apply(literal_eval)\n",
    "\n",
    "# df = df[df['dialog_id'].apply(lambda x: x not in error_dialog_id)]\n",
    "\n",
    "# 20개 이하인 intent는 others로 변경 (question 13개, answer 7개)\n",
    "df[\"intent\"] = df[\"intent\"].apply(lambda x: [\"others\" if item in [\"item_attribute_answer\", \"item_attribute_question\"] else item for item in x])\n",
    "\n",
    "# others 외의 intent가 함께 있으면 others 제거\n",
    "def remove_others_if_not_alone(intents):\n",
    "\tif 'others' in intents and len(intents) > 1:\n",
    "\t\tintents.remove('others')\n",
    "\treturn intents\n",
    "df['intent'] = df['intent'].apply(remove_others_if_not_alone)\n",
    "\n",
    "# initial query와 함께 [remove_filter, continue, accept_response, reject_response, others]가 있으면 제거\n",
    "def preprocess_initial(row):\n",
    "\tif 'initial_query' in row['intent']:\n",
    "\t\tfor intent_to_remove in ['remove_filter', 'continue', 'accept_response', 'reject_response', 'others']:\n",
    "\t\t\tif intent_to_remove in row['intent']:\n",
    "\t\t\t\trow['intent'].remove(intent_to_remove)\n",
    "\treturn row\n",
    "df = df.apply(preprocess_initial, axis=1)\n",
    "\n",
    "#######################\n",
    "def concat_previous_1_rows(group):\n",
    "\tif len(group) < 1:\n",
    "\t\treturn pd.DataFrame()\n",
    "\tgroup = group.copy()\n",
    "\tgroup['content'] = group['content'].shift(1).fillna('') + '. ' + group['content']\n",
    "\tgroup['content'].iloc[0] = group['content'].iloc[0].lstrip('. ')\n",
    "\treturn group\n",
    "\n",
    "def concat_previous_2_rows(group):\n",
    "\tif len(group) < 2:\n",
    "\t\treturn pd.DataFrame()\n",
    "\tgroup = group.copy()\n",
    "\tgroup['content'] = group['content'].shift(2).fillna('') + '. ' + group['content'].shift(1).fillna('') + '. ' + group['content']\n",
    "\tgroup['content'].iloc[0] = group['content'].iloc[0].lstrip('. ')\n",
    "\tgroup['content'].iloc[1] = group['content'].iloc[1].lstrip('. ')\n",
    "\treturn group\n",
    "\n",
    "def concat_previous_4_rows(group):\n",
    "\tif len(group) < 4:\n",
    "\t\treturn pd.DataFrame()\n",
    "\tgroup = group.copy()\n",
    "\tgroup['content'] = group['content'].shift(4).fillna('') + '. ' + group['content'].shift(3).fillna('') + '. ' + group['content'].shift(2).fillna('') + '. ' + group['content'].shift(1).fillna('') + '. ' + group['content']\n",
    "\tfor i in range(4):\n",
    "\t\tgroup['content'].iloc[i] = group['content'].iloc[i].lstrip('. ')\n",
    "\treturn group\n",
    "\n",
    "def concat_previous_6_rows(group):\n",
    "\tif len(group) < 6:\n",
    "\t\treturn pd.DataFrame()\n",
    "\tgroup = group.copy()\n",
    "\tgroup['content'] = group['content'].shift(6).fillna('') + '. ' + group['content'].shift(5).fillna('') + '. ' + group['content'].shift(4).fillna('') + '. ' + group['content'].shift(3).fillna('') + '. ' + group['content'].shift(2).fillna('') + '. ' + group['content'].shift(1).fillna('') + '. ' + group['content']\n",
    "\tfor i in range(6):\n",
    "\t\tgroup['content'].iloc[i] = group['content'].iloc[i].lstrip('. ')\n",
    "\treturn group\n",
    "\n",
    "def concat_previous_8_rows(group):\n",
    "\tif len(group) < 8:\n",
    "\t\treturn pd.DataFrame()\n",
    "\tgroup = group.copy()\n",
    "\tgroup['content'] = (\n",
    "\t\tgroup['content'].shift(8).fillna('') + '. ' +\n",
    "\t\tgroup['content'].shift(7).fillna('') + '. ' +\n",
    "\t\tgroup['content'].shift(6).fillna('') + '. ' + \n",
    "\t\tgroup['content'].shift(5).fillna('') + '. ' + \n",
    "\t\tgroup['content'].shift(4).fillna('') + '. ' + \n",
    "\t\tgroup['content'].shift(3).fillna('') + '. ' + \n",
    "\t\tgroup['content'].shift(2).fillna('') + '. ' + \n",
    "\t\tgroup['content'].shift(1).fillna('') + '. ' + \n",
    "\t\tgroup['content']\n",
    "\t)\n",
    "\tfor i in range(8):\n",
    "\t\tgroup['content'].iloc[i] = group['content'].iloc[i].lstrip('. ')\n",
    "\treturn group\n",
    "\n",
    "# 'dialog_id'별로 그룹화하여 이전 n개 row를 concat\n",
    "df_1 = df.groupby('dialog_id').apply(concat_previous_1_rows).reset_index(drop=True)\n",
    "df_2 = df.groupby('dialog_id').apply(concat_previous_2_rows).reset_index(drop=True)\n",
    "df_4 = df.groupby('dialog_id').apply(concat_previous_4_rows).reset_index(drop=True)\n",
    "df_6 = df.groupby('dialog_id').apply(concat_previous_6_rows).reset_index(drop=True)\n",
    "df_8 = df.groupby('dialog_id').apply(concat_previous_8_rows).reset_index(drop=True)\n",
    "\n",
    "df = df\n",
    "################################\n",
    "\n",
    "#model = DistilBERTClass_noFinetune().to(device)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# def text_to_768(text):\n",
    "#     inputs = tokenizer.encode_plus(\n",
    "#         text,\n",
    "#         None,\n",
    "#         add_special_tokens=True,\n",
    "#         max_length=128,\n",
    "#         padding='max_length',\n",
    "#         return_token_type_ids=False,\n",
    "#         truncation=True,\n",
    "#         return_tensors='pt'\n",
    "#     )\n",
    "#     ids = inputs['input_ids'].to(device)\n",
    "#     mask = inputs['attention_mask'].to(device)\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         output = model(ids, mask)\n",
    "    \n",
    "#     return output.cpu().numpy().flatten()\n",
    "\n",
    "# df['vector'] = df['content'].apply(text_to_768)\n",
    "\n",
    "##########################\n",
    "user_df = df[df['role']=='user']\n",
    "system_df = df[df['role']=='system']\n",
    "\n",
    "del user_df['role']\n",
    "del user_df['music_attribute']\n",
    "del system_df['role']\n",
    "del system_df['music_attribute']\n",
    "\n",
    "def encode_intents(intent_list, intents):\n",
    "\treturn [1 if intent in intent_list else 0 for intent in intents]\n",
    "\n",
    "user_df.loc[:, 'intent'] = user_df['intent'].apply(lambda x: encode_intents(x, user_intents))\n",
    "user_df = user_df.reset_index(drop=True)\n",
    "\n",
    "system_df.loc[:, 'intent'] = system_df['intent'].apply(lambda x: encode_intents(x, system_intents))\n",
    "system_df = system_df.reset_index(drop=True)\n",
    "\n",
    "music_df = df[['index','dialog_id', 'role', 'content', 'music_attribute']]\n",
    "music_df.loc[:, 'music_attribute'] = music_df['music_attribute'].apply(lambda x: encode_intents(x, music_attributes))\n",
    "music_df.rename(columns={'music_attribute': 'intent'}, inplace=True)\n",
    "music_df = music_df.reset_index(drop=True)\n",
    "\n",
    "user_y = torch.stack([torch.tensor(item) for item in user_df['intent']])\n",
    "system_y = torch.stack([torch.tensor(item) for item in system_df['intent']])\n",
    "music_y = torch.stack([torch.tensor(item) for item in music_df['intent']])\n",
    "\n",
    "# Train, Valid Split\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "\n",
    "msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in msss.split(user_df['content'].values, user_y):\n",
    "\tuser_train_df, user_val_df = user_df.iloc[train_index], user_df.iloc[test_index]\n",
    "\tuser_train_y, user_val_y = user_y[train_index], user_y[test_index]\n",
    "\n",
    "msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "\n",
    "for train_index, test_index in msss.split(user_val_df['content'].values, user_val_y):\n",
    "\tuser_val_df, user_test_df = user_val_df.iloc[train_index], user_val_df.iloc[test_index]\n",
    "\tuser_val_y, user_test_y = user_val_y[train_index], user_val_y[test_index]\n",
    "\n",
    "msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in msss.split(system_df['content'].values, system_y):\n",
    "\tsystem_train_df, system_val_df = system_df.iloc[train_index], system_df.iloc[test_index]\n",
    "\tsystem_train_y, system_val_y = system_y[train_index], system_y[test_index]\n",
    "\n",
    "msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "\n",
    "for train_index, test_index in msss.split(system_val_df['content'].values, system_val_y):\n",
    "\tsystem_val_df, system_test_df = system_val_df.iloc[train_index], system_val_df.iloc[test_index]\n",
    "\tsystem_val_y, system_test_y = system_val_y[train_index], system_val_y[test_index]\n",
    " \n",
    "msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in msss.split(music_df['content'].values, music_y):\n",
    "\tmusic_train_df, music_val_df = music_df.iloc[train_index], music_df.iloc[test_index]\n",
    "\tmusic_train_y, music_val_y = music_y[train_index], music_y[test_index]\n",
    "\n",
    "msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "\n",
    "for train_index, test_index in msss.split(music_val_df['content'].values, music_val_y):\n",
    "\tmusic_val_df, music_test_df = music_val_df.iloc[train_index], music_val_df.iloc[test_index]\n",
    "\tmusic_val_y, music_test_y = music_val_y[train_index], music_val_y[test_index]\n",
    "\n",
    "user_train_df = user_train_df.reset_index(drop=True)\n",
    "user_val_df = user_val_df.reset_index(drop=True)\n",
    "user_test_df = user_test_df.reset_index(drop=True)\n",
    "\n",
    "system_train_df = system_train_df.reset_index(drop=True)\n",
    "system_val_df = system_val_df.reset_index(drop=True)\n",
    "system_test_df = system_test_df.reset_index(drop=True)\n",
    "\n",
    "music_train_df = music_train_df.reset_index(drop=True)\n",
    "music_val_df = music_val_df.reset_index(drop=True)\n",
    "music_test_df = music_test_df.reset_index(drop=True)\n",
    "\n",
    "# Generate Data Dictionary\n",
    "\n",
    "data_dict = {\n",
    "\t'user': {\n",
    "\t\t'train': {\n",
    "\t\t\t'dataframe': user_train_df,\n",
    "\t\t\t'label': user_train_y\n",
    "\t\t},\n",
    "\t\t'val': {\n",
    "\t\t\t'dataframe': user_val_df,\n",
    "\t\t\t'label': user_val_y\n",
    "\t\t},\n",
    "  \t\t'test': {\n",
    "\t\t\t'dataframe': user_test_df,\n",
    "\t\t\t'label': user_test_y\n",
    "\t\t}\n",
    "\t},\n",
    "\t'system': {\n",
    "\t\t'train': {\n",
    "\t\t\t'dataframe': system_train_df,\n",
    "\t\t\t'label': system_train_y\n",
    "\t\t},\n",
    "\t\t'val': {\n",
    "\t\t\t'dataframe': system_val_df,\n",
    "\t\t\t'label': system_val_y\n",
    "\t\t},\n",
    "  \t\t'test': {\n",
    "\t\t\t'dataframe': system_test_df,\n",
    "\t\t\t'label': system_test_y\n",
    "\t\t}\n",
    "\t},\n",
    "\t'music': {\n",
    "\t\t'train': {\n",
    "\t\t\t'dataframe': music_train_df,\n",
    "\t\t\t'label': music_train_y\n",
    "\t\t},\n",
    "\t\t'val': {\n",
    "\t\t\t'dataframe': music_val_df,\n",
    "\t\t\t'label': music_val_y\n",
    "\t\t},\n",
    "  \t\t'test': {\n",
    "\t\t\t'dataframe': music_test_df,\n",
    "\t\t\t'label': music_test_y\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "# Define Dataset Class\n",
    "\n",
    "class MultiLabelDataset(Dataset):\n",
    "\tdef __init__(self, dataframe, tokenizer, max_len):\n",
    "\t\tself.tokenizer = tokenizer\n",
    "\t\tself.data = dataframe\n",
    "\t\tself.text = dataframe.content\n",
    "\t\tself.targets = self.data.intent\n",
    "\t\tself.max_len = max_len\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.text)\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\ttext = str(self.text[index])\n",
    "\t\ttext = \" \".join(text.split())\n",
    "\n",
    "\t\ttokens = self.tokenizer.tokenize(text)\n",
    "\t\tif len(tokens) > self.max_len:\n",
    "\t\t\ttokens = tokens[-self.max_len:]\n",
    "\t\ttruncated_text = self.tokenizer.convert_tokens_to_string(tokens)\n",
    "\n",
    "\t\tinputs = self.tokenizer.encode_plus(\n",
    "\t\t\ttruncated_text,\n",
    "\t\t\tNone,\n",
    "\t\t\tadd_special_tokens=True,\n",
    "\t\t\tmax_length=self.max_len,\n",
    "\t\t\tpad_to_max_length=True,\n",
    "\t\t\treturn_token_type_ids=False,\n",
    "   \t\t\ttruncation=True\n",
    "\t\t)\n",
    "\t\tids = inputs['input_ids']\n",
    "\t\tmask = inputs['attention_mask']\n",
    "\n",
    "\t\treturn {\n",
    "\t\t\t'ids': torch.tensor(ids, dtype=torch.int),\n",
    "\t\t\t'mask': torch.tensor(mask, dtype=torch.int),\n",
    "\t\t\t'targets': torch.tensor(self.targets[index], dtype=torch.int)\n",
    "\t\t}\n",
    "  \n",
    "class Dataset_768(Dataset):\n",
    "\tdef __init__(self, dataframe):\n",
    "\t\tself.tokenizer = tokenizer\n",
    "\t\tself.data = dataframe\n",
    "\t\tself.vector = dataframe.vector\n",
    "\t\tself.targets = self.data.intent\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\treturn {\n",
    "\t\t\t'vector': torch.tensor(self.vector, dtype=torch.float),\n",
    "\t\t\t'targets': torch.tensor(self.targets[index], dtype=torch.int)\n",
    "\t\t}\n",
    "\n",
    "# Define Model\n",
    "\n",
    "class DistilBERTClass(nn.Module):\n",
    "\tdef __init__(self, num_intents):\n",
    "\t\tsuper(DistilBERTClass, self).__init__()\n",
    "\t\tself.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\t\tself.fc1 = nn.Sequential(\n",
    "\t\t\tnn.Linear(768, 64),\n",
    "\t\t\tnn.BatchNorm1d(64),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t)\n",
    "\t\tself.fc2 = nn.Sequential(\n",
    "\t\t\tnn.Linear(64, num_intents)\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, input_ids, attention_mask):\n",
    "\t\toutput_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\t\thidden_state = output_1[0]\n",
    "\t\tpooler = hidden_state[:, 0]\n",
    "\t\tpooler = self.fc1(pooler)\n",
    "\t\toutput = self.fc2(pooler)\n",
    "\t\treturn output\n",
    "\n",
    "class DistilBERTClass_noFinetune(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistilBERTClass_noFinetune, self).__init__()\n",
    "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1.last_hidden_state # output_1[0]이랑 같음 (아마도)\n",
    "        pooler = hidden_state[:, 0]\n",
    "        return pooler\n",
    "\n",
    "class MLP_768(nn.Module):\n",
    "\tdef __init__(self, num_intents):\n",
    "\t\tsuper(MLP_768, self).__init__()\n",
    "\t\tself.fc1 = nn.Sequential(\n",
    "\t\t\tnn.Linear(768, 64),\n",
    "\t\t\tnn.BatchNorm1d(64),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t)\n",
    "\t\tself.fc2 = nn.Linear(64, num_intents)\n",
    "\t\tself.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.fc1(x)\n",
    "\t\tx = self.fc2(x)\n",
    "\t\tx = self.sigmoid(x)\n",
    "\t\treturn x\n",
    "\n",
    "# Define functions\n",
    "\n",
    "def decode_intents(encoded_list, data_type):\n",
    "\treturn [intent for intent, flag in zip(intents_dict[data_type], encoded_list) if flag == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: \n",
      "Intents: ['sympathetic_response']\n",
      "Music Attributes: ['tempo']\n",
      "\n",
      "Text: i dont like the vocals in 'the blood', its a bit dark. ill continue to rate these, can you please add some deadmaus, especially 'i remember' with kaskade?\n",
      "Intents: ['add_filter', 'remove_filter']\n",
      "Music Attributes: ['track', 'artist', 'mood', 'vocal']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ExampleDataset(Dataset):\n",
    "\tdef __init__(self, dataframe, tokenizer, max_len):\n",
    "\t\tself.tokenizer = tokenizer\n",
    "\t\tself.data = dataframe\n",
    "\t\tself.text = dataframe.content\n",
    "\t\tself.max_len = max_len\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.text)\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\ttext = str(self.text[index])\n",
    "\t\ttext = \" \".join(text.split())\n",
    "\n",
    "\t\ttokens = self.tokenizer.tokenize(text)\n",
    "\t\tif len(tokens) > self.max_len:\n",
    "\t\t\ttokens = tokens[-self.max_len:]\n",
    "\t\ttruncated_text = self.tokenizer.convert_tokens_to_string(tokens)\n",
    "\n",
    "\t\tinputs = self.tokenizer.encode_plus(\n",
    "\t\t\ttruncated_text,\n",
    "\t\t\tNone,\n",
    "\t\t\tadd_special_tokens=True,\n",
    "\t\t\tmax_length=self.max_len,\n",
    "\t\t\tpad_to_max_length=True,\n",
    "\t\t\treturn_token_type_ids=False,\n",
    "   \t\t\ttruncation=True\n",
    "\t\t)\n",
    "\t\tids = inputs['input_ids']\n",
    "\t\tmask = inputs['attention_mask']\n",
    "\n",
    "\t\treturn {\n",
    "\t\t\t'ids': torch.tensor(ids, dtype=torch.int),\n",
    "\t\t\t'mask': torch.tensor(mask, dtype=torch.int)\n",
    "\t\t}\n",
    "  \n",
    "MAX_LEN = 128\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n",
    "params = {'batch_size': 1, 'shuffle': False, 'num_workers': 4}\n",
    "num_intents_dict = {'user': 8, 'system': 7, 'music': 15}\n",
    "\n",
    "user_best_thresholds = [0.28, 0.24, 0.58, 0.42, 0.32, 0.29, 0.69]\n",
    "system_best_thresholds = [0.49, 0.21, 0.5, 0.23, 0.37, 0.18]\n",
    "music_best_thresholds = [0.52, 0.69, 0.32, 0.14, 0.13, 0.14, 0.15, 0.46, 0.65, 0.1, 0.52, 0.2, 0.14, 0.23]\n",
    "\n",
    "thresholds_dict = {'user': user_best_thresholds, 'system': system_best_thresholds, 'music': music_best_thresholds}\n",
    "\n",
    "def text_to_intent(data_type, text):\n",
    "\tdf = pd.DataFrame({'content': [text]})\n",
    "\t\n",
    "\texample_set = ExampleDataset(df, tokenizer, MAX_LEN)\n",
    "\n",
    "\texample_loader = DataLoader(example_set, **params)\n",
    "\n",
    "\tnum_intents = num_intents_dict[data_type]\n",
    "\n",
    "\tmodel = DistilBERTClass(num_intents)\n",
    "\tif data_type=='music':\n",
    "\t\tmodel.load_state_dict(torch.load('./models/' + data_type + '_model.pth'))\n",
    "\telse:\n",
    "\t\tmodel.load_state_dict(torch.load('./models/' + data_type + '_model_concatone.pth'))\n",
    "\tmodel.to(device)\n",
    "\t\n",
    "\t# Test with best thresholds\n",
    "\tmodel.eval()\n",
    "\tprobability_outputs=[]\n",
    "\twith torch.no_grad():\n",
    "\t\tfor data in example_loader:\n",
    "\t\t\tids = data['ids'].to(device, dtype = torch.int)\n",
    "\t\t\tmask = data['mask'].to(device, dtype = torch.int)\n",
    "\t\t\toutputs = model(ids, mask)\n",
    "\t\t\tprobability_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "\n",
    "\tprobability_outputs = np.array(probability_outputs)[0][:-1]\n",
    "\tbinary_outputs = (probability_outputs >= thresholds_dict[data_type]).astype(int)\n",
    "\tif np.sum(binary_outputs)==0:\n",
    "\t\tbinary_outputs[-1] = True\n",
    "\n",
    "\treturn decode_intents(binary_outputs, data_type)\n",
    "\n",
    "text_dict = [\n",
    "\t{'data_type': 'system', 'text': \"\"},\n",
    "\t{'data_type': 'user', 'text': \"i dont like the vocals in 'the blood', its a bit dark. ill continue to rate these, can you please add some deadmaus, especially 'i remember' with kaskade?\"},\n",
    "]\n",
    "\n",
    "concated_text = \"\"\n",
    "for i in range(len(text_dict)):\n",
    "\tif i==0:\n",
    "\t\tconcated_text = text_dict[i]['text']\n",
    "\telse:\n",
    "\t\tconcated_text = text_dict[i-1]['text'] + '. ' + text_dict[i]['text']\n",
    "  \n",
    "\tintents = text_to_intent(text_dict[i]['data_type'], concated_text)\n",
    "\tattributes = text_to_intent('music', text_dict[i]['text'])\n",
    "  \n",
    "\tprint(f\"Text: {text_dict[i]['text']}\")\n",
    "\tprint(f\"Intents: {intents}\")\n",
    "\tprint(f\"Music Attributes: {attributes}\")\n",
    "\tprint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "634_condafalse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
